{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import json\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import dok_matrix, coo_matrix\n",
    "from sklearn.utils.multiclass import  type_of_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fscore(true_value_matrix, prediction, order_index, product_index, rows, cols, threshold=[0.5]):\n",
    "\n",
    "    prediction_value_matrix = coo_matrix((prediction, (order_index, product_index)), shape=(rows, cols), dtype=np.float32)\n",
    "    # prediction_value_matrix.eliminate_zeros()\n",
    "\n",
    "    return list(map(lambda x: f1_score(true_value_matrix, prediction_value_matrix > x, average='samples'), threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'order_id', u'product_id', u'reordered'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "    # Read data\n",
    "    path = \"../input\"\n",
    "\n",
    "    aisles = pd.read_csv(os.path.join(path, \"aisles.csv\"), dtype={'aisle_id': np.uint8, 'aisle': 'category'})\n",
    "    departments = pd.read_csv(os.path.join(path, \"departments.csv\"),\n",
    "                              dtype={'department_id': np.uint8, 'department': 'category'})\n",
    "    order_prior = pd.read_csv(os.path.join(path, \"order_products__prior.csv\"), dtype={'order_id': np.uint32,\n",
    "                                                                                      'product_id': np.uint16,\n",
    "                                                                                      'add_to_cart_order': np.uint8,\n",
    "                                                                                      'reordered': bool})\n",
    "    order_train = pd.read_csv(os.path.join(path, \"order_products__train.csv\"), dtype={'order_id': np.uint32,\n",
    "                                                                                      'product_id': np.uint16,\n",
    "                                                                                      'add_to_cart_order': np.uint8,\n",
    "                                                                                      'reordered': bool})\n",
    "    orders = pd.read_csv(os.path.join(path, \"orders.csv\"), dtype={'order_id': np.uint32,\n",
    "                                                                  'user_id': np.uint32,\n",
    "                                                                  'eval_set': 'category',\n",
    "                                                                  'order_number': np.uint8,\n",
    "                                                                  'order_dow': np.uint8,\n",
    "                                                                  'order_hour_of_day': np.uint8\n",
    "                                                                  })\n",
    "\n",
    "    products = pd.read_csv(os.path.join(path, \"products.csv\"), dtype={'product_id': np.uint16,\n",
    "                                                                      'aisle_id': np.uint8,\n",
    "                                                                      'department_id': np.uint8})\n",
    "\n",
    "    product_embeddings = pd.read_pickle('../input/product_embeddings.pkl')\n",
    "    embedings = list(range(32))\n",
    "    product_embeddings = product_embeddings[embedings + ['product_id']]\n",
    "\n",
    "    order_train = pd.read_pickle(os.path.join(path, 'chunk_0.pkl'))\n",
    "    order_test = order_train.loc[order_train.eval_set == \"test\", ['order_id', 'product_id']]\n",
    "    order_train = order_train.loc[order_train.eval_set == \"train\", ['order_id',  'product_id',  'reordered']]\n",
    "\n",
    "    product_periods = pd.read_pickle(os.path.join(path, 'product_periods_stat.pkl')).fillna(9999)\n",
    "\n",
    "    print(order_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'order_id', u'product_id', u'add_to_cart_order', u'reordered',\n",
      "       u'user_id', u'eval_set', u'order_number', u'order_dow',\n",
      "       u'order_hour_of_day', u'days_since_prior_order'],\n",
      "      dtype='object')\n",
      "Index([u'user_id', u'reordered'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "    #Join data\n",
    "\n",
    "    prob = pd.merge(order_prior, orders, on='order_id')\n",
    "    print(prob.columns)\n",
    "    prob = prob.groupby(['product_id', 'user_id'])\\\n",
    "        .agg({'reordered':'sum', 'user_id': 'size'})\n",
    "    print(prob.columns)\n",
    "\n",
    "    prob.rename(columns={'sum': 'reordered',\n",
    "                         'user_id': 'total'}, inplace=True)\n",
    "\n",
    "    prob.reordered = (prob.reordered > 0).astype(np.float32)\n",
    "    prob.total = (prob.total > 0).astype(np.float32)\n",
    "    prob['reorder_prob'] = prob.reordered / prob.total\n",
    "    prob = prob.reset_index()\n",
    "    prob = prob.groupby('product_id').agg({'reorder_prob': 'mean'}).rename(columns={'mean': 'reorder_prob'})\\\n",
    "        .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    prod_stat = order_prior.groupby('product_id').agg({'reordered': ['sum', 'size'],\n",
    "                                                       'add_to_cart_order':'mean'})\n",
    "    prod_stat.columns = prod_stat.columns.levels[1]\n",
    "    prod_stat.rename(columns={'sum':'prod_reorders',\n",
    "                              'size':'prod_orders',\n",
    "                              'mean': 'prod_add_to_card_mean'}, inplace=True)\n",
    "    prod_stat.reset_index(inplace=True)\n",
    "\n",
    "    prod_stat['reorder_ration'] = prod_stat['prod_reorders'] / prod_stat['prod_orders']\n",
    "    prod_stat = pd.merge(prod_stat, prob, on='product_id')\n",
    "    \n",
    "    del prob\n",
    "\n",
    "    # prod_stat.drop(['prod_reorders'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    user_stat = orders.loc[orders.eval_set == 'prior', :].groupby('user_id').agg({'order_number': 'max',\n",
    "                                                                                  'days_since_prior_order': ['sum',\n",
    "                                                                                                             'mean',\n",
    "                                                                                                             'median']})\n",
    "    user_stat.columns = user_stat.columns.droplevel(0)\n",
    "    user_stat.rename(columns={'max': 'user_orders',\n",
    "                              'sum': 'user_order_starts_at',\n",
    "                              'mean': 'user_mean_days_since_prior',\n",
    "                              'median': 'user_median_days_since_prior'}, inplace=True)\n",
    "    user_stat.reset_index(inplace=True)\n",
    "\n",
    "    orders_products = pd.merge(orders, order_prior, on=\"order_id\")\n",
    "\n",
    "    user_order_stat = orders_products.groupby('user_id').agg({'user_id': 'size',\n",
    "                                                              'reordered': 'sum',\n",
    "                                                              \"product_id\": lambda x: x.nunique()})\n",
    "\n",
    "    user_order_stat.rename(columns={'user_id': 'user_total_products',\n",
    "                                    'product_id': 'user_distinct_products',\n",
    "                                    'reordered': 'user_reorder_ratio'}, inplace=True)\n",
    "\n",
    "    user_order_stat.reset_index(inplace=True)\n",
    "    user_order_stat.user_reorder_ratio = user_order_stat.user_reorder_ratio / user_order_stat.user_total_products\n",
    "\n",
    "    user_stat = pd.merge(user_stat, user_order_stat, on='user_id')\n",
    "    del user_order_stat\n",
    "    user_stat['user_average_basket'] = user_stat.user_total_products / user_stat.user_orders\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prd = orders_products.copy()\n",
    "prd['product_time'] = prd.groupby(['user_id', 'product_id']).cumcount()\n",
    "gp = prd.groupby(['product_id'])['product_time'].value_counts()\n",
    "del prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_stat = pd.merge(prod_stat,\n",
    "    pd.merge(\n",
    "        pd.merge(gp[:,1].reset_index(name=\"prod_first_orders\"), \n",
    "                 gp[:,2].reset_index(name=\"prod_second_orders\"), how='outer'),\n",
    "         gp[:,3].reset_index(name=\"prod_third_orders\"), how='outer'), how='left')\n",
    "del gp\n",
    "prod_stat['prod_reorder_prob1'] = prod_stat.prod_second_orders / prod_stat.prod_first_orders\n",
    "prod_stat['prod_reorder_prob2'] = prod_stat.prod_third_orders / prod_stat.prod_first_orders\n",
    "prod_stat['prod_reorder_times'] = 1 + prod_stat.prod_reorders / prod_stat.prod_first_orders\n",
    "prod_stat = prod_stat.drop(['prod_first_orders', 'prod_second_orders', 'prod_third_orders'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206209, 2) (206209, 9)\n"
     ]
    }
   ],
   "source": [
    "    us = orders.loc[orders.eval_set != \"prior\", ['user_id', 'days_since_prior_order']]\n",
    "    us.rename(columns={'days_since_prior_order': 'time_since_last_order'}, inplace=True)\n",
    "    user_stat = pd.merge(user_stat, us, on='user_id', how='left')\n",
    "    del us    \n",
    "    user_stat['user_order_recency'] = user_stat.time_since_last_order / user_stat.user_mean_days_since_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8474661, 3)\n",
      "(8474661, 6)\n",
      "(8474661, 12)\n",
      "(8474661, 14)\n",
      "(8474661, 16)\n",
      "(8474661, 17)\n",
      "(8474661, 18)\n",
      "(8338473, 56)\n",
      "data is joined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6e37db05d5b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mprod_usr_reordered\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0morder_prior\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0maisles\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mdepartments\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prob' is not defined"
     ]
    }
   ],
   "source": [
    "    ########################### products\n",
    "\n",
    "    prod_usr = orders_products.groupby(['product_id']).agg({'user_id': lambda x: x.nunique()})\n",
    "    prod_usr.rename(columns={'user_id':'prod_users_unq'}, inplace=True)\n",
    "    prod_usr.reset_index(inplace=True)\n",
    "\n",
    "    prod_usr_reordered = orders_products.loc[orders_products.reordered, :].groupby(['product_id']).agg({'user_id': lambda x: x.nunique()})\n",
    "    prod_usr_reordered.rename(columns={'user_id': 'prod_users_unq_reordered'}, inplace=True)\n",
    "    prod_usr_reordered.reset_index(inplace=True)\n",
    "\n",
    "    order_stat = orders_products.groupby('order_id').agg({'order_id': 'size'}) \\\n",
    "        .rename(columns={'order_id': 'order_size'}).reset_index()\n",
    "\n",
    "    orders_products = pd.merge(orders_products, order_stat, on='order_id')\n",
    "    orders_products['add_to_cart_order_inverted'] = orders_products.order_size - orders_products.add_to_cart_order\n",
    "    orders_products['add_to_cart_order_relative'] = orders_products.add_to_cart_order / orders_products.order_size\n",
    "\n",
    "    data = orders_products.groupby(['user_id', 'product_id']).agg({'user_id': 'size',\n",
    "                                                                   'order_number': ['min', 'max'],\n",
    "                                                                   'add_to_cart_order': ['mean', 'median'],\n",
    "                                                                   'days_since_prior_order': ['mean', 'median'],\n",
    "                                                                   'order_dow': ['mean', 'median'],\n",
    "                                                                   'order_hour_of_day': ['mean', 'median'],\n",
    "                                                                   'add_to_cart_order_inverted': ['mean', 'median'],\n",
    "                                                                   'add_to_cart_order_relative': ['mean', 'median'],\n",
    "                                                                   'reordered': ['sum']})\n",
    "\n",
    "    data.columns = data.columns.droplevel(0)\n",
    "    data.columns = ['up_orders', 'up_first_order', 'up_last_order', 'up_mean_cart_position', 'up_median_cart_position',\n",
    "                    'days_since_prior_order_mean', 'days_since_prior_order_median', 'order_dow_mean',\n",
    "                    'order_dow_median',\n",
    "                    'order_hour_of_day_mean', 'order_hour_of_day_median',\n",
    "                    'add_to_cart_order_inverted_mean', 'add_to_cart_order_inverted_median',\n",
    "                    'add_to_cart_order_relative_mean', 'add_to_cart_order_relative_median',\n",
    "                    'reordered_sum'\n",
    "                    ]\n",
    "\n",
    "    data['user_product_reordered_ratio'] = (data.reordered_sum + 1.0) / data.up_orders\n",
    "\n",
    "    # data['first_order'] = data['up_orders'] > 0\n",
    "    # data['second_order'] = data['up_orders'] > 1\n",
    "    #\n",
    "    # data.groupby('product_id')['']\n",
    "\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    data = pd.merge(data, prod_stat, on='product_id')\n",
    "    data = pd.merge(data, user_stat, on='user_id')\n",
    "\n",
    "    data['up_order_rate'] = data.up_orders / data.user_orders\n",
    "    data['up_orders_since_last_order'] = data.user_orders - data.up_last_order\n",
    "    data['up_order_rate_since_first_order'] = data.user_orders / (data.user_orders - data.up_first_order + 1)\n",
    "\n",
    "    ############################\n",
    "\n",
    "    user_dep_stat = pd.read_pickle('../input/user_department_products.pkl')\n",
    "    user_aisle_stat = pd.read_pickle('../input/user_aisle_products.pkl')\n",
    "\n",
    "    ############### train\n",
    "\n",
    "    print(order_train.shape)\n",
    "    order_train = pd.merge(order_train, products, on='product_id')\n",
    "    print(order_train.shape)\n",
    "    order_train = pd.merge(order_train, orders, on='order_id')\n",
    "    print(order_train.shape)\n",
    "    order_train = pd.merge(order_train, user_dep_stat, on=['user_id', 'department_id'])\n",
    "    print(order_train.shape)\n",
    "    order_train = pd.merge(order_train, user_aisle_stat, on=['user_id', 'aisle_id'])\n",
    "    print(order_train.shape)\n",
    "\n",
    "    order_train = pd.merge(order_train, prod_usr, on='product_id')\n",
    "    print(order_train.shape)\n",
    "    order_train = pd.merge(order_train, prod_usr_reordered, on='product_id', how='left')\n",
    "    order_train.prod_users_unq_reordered.fillna(0, inplace=True)\n",
    "    print(order_train.shape)\n",
    "\n",
    "    order_train = pd.merge(order_train, data, on=['product_id', 'user_id'])\n",
    "    print(order_train.shape)\n",
    "\n",
    "    order_train['aisle_reordered_ratio'] = order_train.aisle_reordered / order_train.user_orders\n",
    "    order_train['dep_reordered_ratio'] = order_train.dep_reordered / order_train.user_orders\n",
    "\n",
    "    order_train = pd.merge(order_train, product_periods, on=['user_id',  'product_id'])\n",
    "\n",
    "    ##############\n",
    "\n",
    "    order_test = pd.merge(order_test, products, on='product_id')\n",
    "    order_test = pd.merge(order_test, orders, on='order_id')\n",
    "    order_test = pd.merge(order_test, user_dep_stat, on=['user_id', 'department_id'])\n",
    "    order_test = pd.merge(order_test, user_aisle_stat, on=['user_id', 'aisle_id'])\n",
    "\n",
    "    order_test = pd.merge(order_test, prod_usr, on='product_id')\n",
    "    order_test = pd.merge(order_test, prod_usr_reordered, on='product_id', how='left')\n",
    "    order_train.prod_users_unq_reordered.fillna(0, inplace=True)\n",
    "\n",
    "    order_test = pd.merge(order_test, data, on=['product_id', 'user_id'])\n",
    "\n",
    "    order_test['aisle_reordered_ratio'] = order_test.aisle_reordered / order_test.user_orders\n",
    "    order_test['dep_reordered_ratio'] = order_test.dep_reordered / order_test.user_orders\n",
    "\n",
    "    order_test = pd.merge(order_test, product_periods, on=['user_id', 'product_id'])\n",
    "\n",
    "    order_train = pd.merge(order_train, product_embeddings, on=['product_id'])\n",
    "    order_test = pd.merge(order_test, product_embeddings, on=['product_id'])\n",
    "\n",
    "    print('data is joined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    del user_dep_stat\n",
    "    del user_aisle_stat\n",
    "    del product_embeddings\n",
    "    del product_periods\n",
    "    del orders\n",
    "    del products\n",
    "    del prod_usr \n",
    "    del prod_usr_reordered\n",
    "    del order_prior\n",
    "    del aisles\n",
    "    del departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('not included', set(['user_id', 'reordered', 'order_id', 'eval_set', 'order_dow_median', 'days_since_prior_order_median', 'product_name', 'add_to_cart_order_relative_median', 'order_hour_of_day_median', 'up_median_cart_position', 'user_median_days_since_prior', 'add_to_cart_order_inverted_median']))\n"
     ]
    }
   ],
   "source": [
    "    features = [\n",
    "        # 'reordered_dow_ration', 'reordered_dow', 'reordered_dow_size',\n",
    "        # 'reordered_prev', 'add_to_cart_order_prev', 'order_dow_prev', 'order_hour_of_day_prev',\n",
    "        'user_order_recency', 'time_since_last_order',  'prod_reorder_times',\n",
    "        'prod_reorder_prob1', 'prod_reorder_prob2',\n",
    "        'user_product_reordered_ratio', 'reordered_sum',\n",
    "        'add_to_cart_order_inverted_mean', 'add_to_cart_order_relative_mean',\n",
    "        'reorder_prob',\n",
    "        'last', 'prev1', 'prev2', 'median', 'mean',\n",
    "        'dep_reordered_ratio', 'aisle_reordered_ratio',\n",
    "        'aisle_products',\n",
    "        'aisle_reordered',\n",
    "        'dep_products',\n",
    "        'dep_reordered',\n",
    "        'prod_users_unq', 'prod_users_unq_reordered',\n",
    "        'order_number', 'prod_add_to_card_mean',\n",
    "        'days_since_prior_order',\n",
    "        'order_dow', 'order_hour_of_day',\n",
    "        'reorder_ration',\n",
    "        'user_orders', 'user_order_starts_at', 'user_mean_days_since_prior',\n",
    "        # 'user_median_days_since_prior',\n",
    "        'user_average_basket', 'user_distinct_products', 'user_reorder_ratio', 'user_total_products',\n",
    "        'prod_orders', 'prod_reorders',\n",
    "        'up_order_rate', 'up_orders_since_last_order', 'up_order_rate_since_first_order',\n",
    "        'up_orders', 'up_first_order', 'up_last_order', 'up_mean_cart_position',\n",
    "        # 'up_median_cart_position',\n",
    "        'days_since_prior_order_mean',\n",
    "        # 'days_since_prior_order_median',\n",
    "        'order_dow_mean',\n",
    "        # 'order_dow_median',\n",
    "        'order_hour_of_day_mean',\n",
    "        # 'order_hour_of_day_median'\n",
    "    ]\n",
    "    features.extend(embedings)\n",
    "    categories = ['product_id', 'aisle_id', 'department_id']\n",
    "    features.extend(embedings)\n",
    "    cat_features = ','.join(map(lambda x: str(x + len(features)), range(len(categories))))\n",
    "    features.extend(categories)    \n",
    "    print('not included', set(order_train.columns.tolist()) - set(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8338473, 115)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6a734904a8a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0morder_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m8474661\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlgb_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    data = order_train[features]\n",
    "    labels = order_train[['reordered']].values.astype(np.float32).flatten()\n",
    "    del order_train\n",
    "\n",
    "    assert data.shape[0] == 8474661\n",
    "\n",
    "    lgb_train = lgb.Dataset(data, labels, categorical_feature=cat_features)\n",
    "    del data\n",
    "    del labels\n",
    "\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': {'binary_logloss', 'auc'},\n",
    "        'num_leaves': 256,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'max_depth': 12,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.6,\n",
    "        # 'bagging_fraction': 0.9,\n",
    "        # 'bagging_freq': 3,\n",
    "        'verbose': 1\n",
    "    }\n",
    "\n",
    "    print('Start training...')\n",
    "    # train\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=380)\n",
    "\n",
    "    data_val = order_test[features]\n",
    "    prediction = gbm.predict(data_val)\n",
    "\n",
    "    orders = order_test.order_id.values\n",
    "    products = order_test.product_id.values\n",
    "\n",
    "    result = pd.DataFrame({'product_id': products, 'order_id': orders, 'prediction': prediction})\n",
    "    result.to_pickle('../input/prediction_lgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
